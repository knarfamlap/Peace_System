{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KaadkLYf5_8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aK8KXoN8f6AD"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "CSV_LOCATION = \"peace_sys.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAN_CULTURES = ['Gilbertese', 'Rhade', 'Yanomamo', 'Kurds', 'Yapese']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYxbDen_f6AI"
   },
   "outputs": [],
   "source": [
    "VARS = {'ID1.1Over' : 'Overarching Identity', 'Int2.4Hist' : 'Interconnected Historically', \n",
    "        'Int2.2Econ' : 'Interconnected Economically', 'Dep3.3Econ' : 'Interdependent Economically', \n",
    "        'Dep3.2Ecol' : 'Interdependent Ecologically', 'NWNorm5.1': 'Non-Warring Norms', \n",
    "        'NWVal4.1' : 'Non-Warring Values', 'SymP6': 'Peace Symbols', 'RitP6' : 'Peace Rituals', \n",
    "        'CM8.5Peace' : 'Peaceful Conflict Management Overall'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUKVvBk6f6AL"
   },
   "outputs": [],
   "source": [
    "def mode(x):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "        x: 1D numpy array\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "        scalar representing the mode of the arr\n",
    "    \"\"\"\n",
    "    # count number of 1 in x\n",
    "    one_sum = np.count_nonzero(x == 1)\n",
    "    # count number of 0 in x\n",
    "    zero_sum = np.count_nonzero(x == 0)\n",
    "    # return mode if a mode exists\n",
    "    if one_sum > zero_sum:\n",
    "        return 1\n",
    "\n",
    "    if one_sum == zero_sum:\n",
    "        return 2\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgUcnGcUf6AP"
   },
   "outputs": [],
   "source": [
    "def logistic_sigmoid(x, beta, intercept):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        x: scalar with score [1-4] for each factor for each obeservation.\n",
    "        betas: scalar betas extracted from logreg model.\n",
    "        intercept: number extracted from logreg model. Denoted as beta_0\n",
    "    Returns:\n",
    "        scalar that represent the probability\n",
    "    \"\"\"\n",
    "    \n",
    "    return 1 / (1 + np.exp(-(intercept + beta * x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLgpoEppf6AR"
   },
   "outputs": [],
   "source": [
    "def train_on_feature(X, y):\n",
    "    \"\"\"\n",
    "    Trains logistic regression model on 1 feature.  X and y must have equal dimensions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: dataframe containing 1 column. Shape is (m, 1). m is the number of rows.\n",
    "        X can contain Nan values.\n",
    "    y: dataframe containing labels for each obeservation in X. \n",
    "        Same is (m, 1). m is the number of rows. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "            \n",
    "    \"\"\"\n",
    "    # store the freature name for reference\n",
    "    feature_name = X.columns[0]\n",
    "    label = 'label'\n",
    "    # concatenate feature and labels into one df\n",
    "    concat_df = pd.DataFrame({feature_name: list(X[feature_name]), label: y})\n",
    "    # drop nan values\n",
    "    concat_df = concat_df.dropna()\n",
    "    # reasign values to feature df\n",
    "    X = pd.DataFrame(concat_df[feature_name])\n",
    "    # reasign values to label df\n",
    "    y = pd.DataFrame(concat_df[label])\n",
    "    # init model\n",
    "    logreg = LogisticRegression(random_state=SEED)\n",
    "    # train model\n",
    "    logreg.fit(X, y[label].ravel())\n",
    "    \n",
    "    intercept = logreg.intercept_[0]\n",
    "    beta = logreg.coef_[0][0]\n",
    "    \n",
    "    return beta, intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hetWCxuPf6AT"
   },
   "outputs": [],
   "source": [
    "def generate_betas_and_intercepts(X, y):\n",
    "    \"\"\"\n",
    "    Genearates beta, and intercept for each feature in X. \n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    X: dataframe containing all observations. Shape (m, n)\n",
    "    y: dataframe containg all labels for each observaation in X. Shape (m, 1)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    res: dataframe containg beta and intercepts for each feature. res columns have the pattern\n",
    "        (beta, intercept)\n",
    "    \n",
    "    \"\"\"\n",
    "    # store beta and intercept for each feature\n",
    "    res = pd.DataFrame()\n",
    "    \n",
    "    for col in X.columns:\n",
    "        # get the df for col\n",
    "        feature_df = pd.DataFrame(X[col])\n",
    "        # get prediciton\n",
    "        beta, intercept = train_on_feature(feature_df, y)\n",
    "        # add to the other predictions\n",
    "        res[col] = [(beta, intercept)]\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mIwCD1yKf6AU"
   },
   "outputs": [],
   "source": [
    "def predict_with_given_betas_and_intercepts(X, betas_intercepts):\n",
    "    \"\"\"\n",
    "    Predict a 0 or 1 value for each observation given the beta and intercept for each feature\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    X: dataframe containing all observations. Shape (m, n)\n",
    "    betas_intercepts: dataframe containing one row. each cell contains a tuple described as (beta, intercept).\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    y_preds: array that cointains a predictions for each culture(observation). There are 42 observations\n",
    "    \n",
    "    \"\"\"\n",
    "    # get the humber of rows\n",
    "    num_rows = X.shape[0]\n",
    "    y_preds = []\n",
    "    \n",
    "    for i in range(num_rows):\n",
    "        # get the current row\n",
    "        curr = X.iloc[i]\n",
    "        # create copy of betas_intercepts df\n",
    "        beta_inter_copy = betas_intercepts\n",
    "        # append the row to the copy\n",
    "        concat_df = beta_inter_copy.append(curr)\n",
    "        # drop columns that have missing values\n",
    "        concat_df = concat_df.dropna(axis=1)\n",
    "        # contains all the prediction for each observation \n",
    "        preds = []\n",
    "        for col in concat_df.columns:\n",
    "            # get the beta\n",
    "            beta = concat_df[col].iloc[0][0] \n",
    "            # get the intercept\n",
    "            intercept = concat_df[col].iloc[0][1]\n",
    "            # get the observation that is an int from 1-4\n",
    "            observation = concat_df[col].iloc[1]\n",
    "            obs_pred = logistic_sigmoid(observation, beta, intercept)\n",
    "            # append to predictions arr\n",
    "            preds.append(obs_pred)\n",
    "        # convert values >= 0.5 to 1, otherwise 0\n",
    "        preds = list(map(lambda x: 1 if x >= 0.5 else 0, preds))\n",
    "        # get the mode to give a final classification\n",
    "        preds_mode = mode(np.array(preds))\n",
    "        y_preds.append(preds_mode)\n",
    "        \n",
    "    return y_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiGLRc0rf6AV"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cultures that contain all nan vals\n",
    "df = df[df['Name'].map(lambda x: x not in NAN_CULTURES)]\n",
    "# reset indexing of dataframe\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdCisxaVf6AW"
   },
   "outputs": [],
   "source": [
    "X = df[VARS.keys()].replace(9, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmYBA2zhf6AX"
   },
   "outputs": [],
   "source": [
    "y = df[\"PSysRec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop\n",
    "num_rows = X.shape[0]\n",
    "y_preds = [] \n",
    "\n",
    "for i in range(num_rows):\n",
    "    # get the test culture\n",
    "    X_test = X[i:i+1]\n",
    "    y_test = X[i:i+1]\n",
    "    \n",
    "    # create train sets without single culture\n",
    "    X_train = X.drop(index=i, axis=1)\n",
    "    y_train = y.drop(index=i, axis=1)\n",
    "    \n",
    "    # get learned betas from logreg\n",
    "    betas_inter = generate_betas_and_intercepts(X_train, y_train)\n",
    "    \n",
    "    # returns prediction for a single culture\n",
    "    y_hat = predict_with_given_betas_and_intercepts(X_test, betas_inter)[0]\n",
    "    y_preds.append(y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['savefig.facecolor'] = 'white'\n",
    "conf_matrix_plot = sns.heatmap(conf_matrix, annot=True)\n",
    "plt.title('Confusion matrix,   0=non-peace, 1=peace', y=1.1)\n",
    "\n",
    "plt.ylabel('Actual label')\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix_plot.get_figure().savefig('indep_keys_conf_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(data={'Name': df.Name, 'Actual': y, 'Prediction': y_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_excel('indep_keys_preds.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_val(x):\n",
    "    if x <= 1:\n",
    "        return 1\n",
    "    \n",
    "    return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.applymap(lambda x: shift_val(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop\n",
    "num_rows = X.shape[0]\n",
    "y_preds = [] \n",
    "\n",
    "for i in range(num_rows):\n",
    "    # get the test culture\n",
    "    X_test = X[i:i+1]\n",
    "    y_test = X[i:i+1]\n",
    "    \n",
    "    # create train sets without single culture\n",
    "    X_train = X.drop(index=i, axis=1)\n",
    "    y_train = y.drop(index=i, axis=1)\n",
    "    \n",
    "    # get learned betas from logreg\n",
    "    betas_inter = generate_betas_and_intercepts(X_train, y_train)\n",
    "    \n",
    "    # returns prediction for a single culture\n",
    "    y_hat = predict_with_given_betas_and_intercepts(X_test, betas_inter)[0]\n",
    "    y_preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_conf_matrix = confusion_matrix(y, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['savefig.facecolor'] = 'white'\n",
    "conf_matrix_plot = sns.heatmap(transformed_conf_matrix, annot=True)\n",
    "plt.title('Confusion matrix,   0=non-peace, 1=peace', y=1.1)\n",
    "\n",
    "plt.ylabel('Actual label')\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "indep_keys.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
